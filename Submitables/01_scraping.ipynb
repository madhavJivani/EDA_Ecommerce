{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "searchstrings = [\"iphone\", \"oneplus\", \"oppo\", \"realme\", \"samsung\", \"vivo\", \"xiaomi\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to Raw-Csvs/iphone/page_1.csv\n",
      "Data exported to Raw-Csvs/iphone/page_2.csv\n",
      "Data exported to Raw-Csvs/iphone/page_3.csv\n",
      "Data exported to Raw-Csvs/iphone/page_4.csv\n",
      "Data exported to Raw-Csvs/iphone/page_5.csv\n",
      "Data exported to Raw-Csvs/oneplus/page_1.csv\n",
      "Data exported to Raw-Csvs/oneplus/page_2.csv\n",
      "Data exported to Raw-Csvs/oneplus/page_3.csv\n",
      "Data exported to Raw-Csvs/oneplus/page_4.csv\n",
      "Data exported to Raw-Csvs/oneplus/page_5.csv\n",
      "Data exported to Raw-Csvs/oppo/page_1.csv\n",
      "Data exported to Raw-Csvs/oppo/page_2.csv\n",
      "Data exported to Raw-Csvs/oppo/page_3.csv\n",
      "Data exported to Raw-Csvs/oppo/page_4.csv\n",
      "Data exported to Raw-Csvs/oppo/page_5.csv\n",
      "Data exported to Raw-Csvs/realme/page_1.csv\n",
      "Data exported to Raw-Csvs/realme/page_2.csv\n",
      "Data exported to Raw-Csvs/realme/page_3.csv\n",
      "Data exported to Raw-Csvs/realme/page_4.csv\n",
      "Data exported to Raw-Csvs/realme/page_5.csv\n",
      "Data exported to Raw-Csvs/samsung/page_1.csv\n",
      "Data exported to Raw-Csvs/samsung/page_2.csv\n",
      "Data exported to Raw-Csvs/samsung/page_3.csv\n",
      "Data exported to Raw-Csvs/samsung/page_4.csv\n",
      "Data exported to Raw-Csvs/samsung/page_5.csv\n",
      "Data exported to Raw-Csvs/vivo/page_1.csv\n",
      "Data exported to Raw-Csvs/vivo/page_2.csv\n",
      "Data exported to Raw-Csvs/vivo/page_3.csv\n",
      "Data exported to Raw-Csvs/vivo/page_4.csv\n",
      "Data exported to Raw-Csvs/vivo/page_5.csv\n",
      "Data exported to Raw-Csvs/xiaomi/page_1.csv\n",
      "Data exported to Raw-Csvs/xiaomi/page_2.csv\n",
      "Data exported to Raw-Csvs/xiaomi/page_3.csv\n",
      "Data exported to Raw-Csvs/xiaomi/page_4.csv\n",
      "Data exported to Raw-Csvs/xiaomi/page_5.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for searchstring in searchstrings:\n",
    "    # Base URL for the Amazon search page\n",
    "    base_url = f'https://www.amazon.in/s?k={searchstring}'\n",
    "    base_url = base_url + '&page={}'\n",
    "    # Headers to simulate a real browser request\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\"\n",
    "    }\n",
    "\n",
    "    # Loop through pages, adjust the range to control the number of pages to scrape\n",
    "    for page in range(1, 6):  # Scraping pages 1 to 5\n",
    "        url = base_url.format(page)\n",
    "        \n",
    "        # Send a GET request to the Amazon URL\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # List to store product details for each page\n",
    "            products = []\n",
    "            \n",
    "            # Find all product sections on the page\n",
    "            product_sections = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "            \n",
    "            # Loop through each product section and extract details\n",
    "            for product_section in product_sections:\n",
    "                # Extract product name\n",
    "                name_tag = product_section.find('span', class_='a-size-medium a-color-base a-text-normal')\n",
    "                product_name = name_tag.text.strip() if name_tag else \"N/A\"\n",
    "                \n",
    "                # Extract rating (stars)\n",
    "                rating_tag = product_section.find('span', class_='a-icon-alt')\n",
    "                product_rating = rating_tag.text.split()[0] if rating_tag else \"N/A\"  # e.g., '4.5 out of 5 stars'\n",
    "                \n",
    "                # Extract number of reviews\n",
    "                reviews_tag = product_section.find('span', class_='a-size-base s-underline-text')\n",
    "                product_reviews = reviews_tag.text.strip() if reviews_tag else \"N/A\"\n",
    "                \n",
    "                # Extract 'Bought last month' text (if available)\n",
    "                bought_last_month_tag = product_section.find('span', class_='a-size-base a-color-secondary')\n",
    "                bought_last_month = bought_last_month_tag.text.strip() if bought_last_month_tag else \"N/A\"\n",
    "                \n",
    "                # Extract current MRP (price)\n",
    "                current_price_tag = product_section.find('span', class_='a-price-whole')\n",
    "                current_price = current_price_tag.text.replace(',', '').strip() if current_price_tag else \"N/A\"\n",
    "                \n",
    "                # Extract dashed (original) MRP\n",
    "                original_price_tag = product_section.find('span', class_='a-price a-text-price')\n",
    "                dashed_mrp = original_price_tag.find('span', class_='a-offscreen').text.replace(',', '').strip() if original_price_tag else \"N/A\"\n",
    "                \n",
    "                # Extract discount percentage\n",
    "                discount_tag = product_section.find('span', string=lambda text: text and '(' in text and '%' in text)\n",
    "                discount_percentage = discount_tag.text if discount_tag else \"N/A\"\n",
    "\n",
    "                # Check for free delivery status\n",
    "                free_delivery_tag = product_section.find('span', string=lambda x: x and 'free delivery' in x.lower())\n",
    "                free_delivery = \"Yes\" if free_delivery_tag else \"No\"\n",
    "\n",
    "                # Append all product details to the list\n",
    "                products.append({\n",
    "                    'Product Name': product_name,\n",
    "                    'Rating (Stars)': product_rating,\n",
    "                    'Number of Reviews': product_reviews,\n",
    "                    'Bought Last Month': bought_last_month,\n",
    "                    'Current MRP': current_price,\n",
    "                    'Dashed MRP': dashed_mrp,\n",
    "                    'Discount (%)': discount_percentage,\n",
    "                    'Free Delivery': free_delivery\n",
    "                })\n",
    "            \n",
    "            # Convert list of products to DataFrame\n",
    "            df = pd.DataFrame(products)\n",
    "            \n",
    "            # Create directory if it doesn't exist\n",
    "            directory = f'Raw-Csvs/{searchstring}'\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            \n",
    "            # Save each page's data to a separate CSV file\n",
    "            file_name = f'{directory}/page_{page}.csv'\n",
    "            df.to_csv(file_name, index=False)\n",
    "            print(f\"Data exported to {file_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve page {page}. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brand in searchstrings:\n",
    "    df1 = pd.read_csv(f'Raw-Csvs/{brand}/page_1.csv')\n",
    "    df2 = pd.read_csv(f'Raw-Csvs/{brand}/page_2.csv')\n",
    "    df3 = pd.read_csv(f'Raw-Csvs/{brand}/page_3.csv')\n",
    "    df4 = pd.read_csv(f'Raw-Csvs/{brand}/page_4.csv')\n",
    "    df5 = pd.read_csv(f'Raw-Csvs/{brand}/page_5.csv')\n",
    "\n",
    "    df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "    df = df.drop_duplicates(subset='Product Name')\n",
    "    df.to_csv(f'Raw-csvs/{brand}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
